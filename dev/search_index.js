var documenterSearchIndex = {"docs":
[{"location":"man/painting/#Estimating-ancestry","page":"Estimating ancestry","title":"Estimating ancestry","text":"","category":"section"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"If samples in the reference haplotype panel are labeled with a population origin, MendelImpute can also be used for:","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"Estimate admixed proportions\nChromosome painting","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"We use the 1000 genomes chromosome 22 as illustration. Example code to generate plots are presented. ","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"# first load all necessary packages\nusing MendelImpute\nusing VCFTools\nusing GeneticVariation\nusing Random\nusing DataFrames\nusing Plots\nusing JLSO","category":"page"},{"location":"man/painting/#Data-preparation","page":"Estimating ancestry","title":"Data preparation","text":"","category":"section"},{"location":"man/painting/#Step-0.-Filter-chromosome-data","page":"Estimating ancestry","title":"Step 0. Filter chromosome data","text":"","category":"section"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"The original chromosome data are filtered into target and reference panels. Follow detailed example in Phasing and Imputation to obtain the same data.","category":"page"},{"location":"man/painting/#Step-1.-Get-population-data","page":"Estimating ancestry","title":"Step 1. Get population data","text":"","category":"section"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"Download population code for each 1000 genomes sample via the command below (note wget will probably not work on non-Mac OS). Different population code is explained here. ","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"# run this code in terminal\n# wget -r -l3 -N --no-parent ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/data_collections/1000_genomes_project/data/","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"For easier processing, copy the country of origin data into a folder called data. It should look contain these subfolders (where each population code contains the sample IDs that belong to the population):","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":";ls data","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"ACB\nASW\nBEB\nCDX\nCEU\nCHB\nCHS\nCLM\nESN\nFIN\nGBR\nGIH\nGWD\nIBS\nITU\nJPT\nKHV\nLWK\nMSL\nMXL\nPEL\nPJL\nPUR\nSTU\nTSI\nYRI","category":"page"},{"location":"man/painting/#Step-2.-Process-each-sample's-population-origin","page":"Estimating ancestry","title":"Step 2. Process each sample's population origin","text":"","category":"section"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"The goal here is to create a Dict{key, value} where each key is a sample ID and the value is the population code. This will be used for both the paint and composition function.","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"Here the population origin for different samples are encoded in weird subfolder directory way. We process them into the desired dictionary structure.","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"df = DataFrame(sample = String[], population = String[])\nrefID_to_population = Dict{String, String}()\nfor population in readdir(\"data/\")\n    population == \".DS_Store\" && continue # skip auxiliary files\n    for sample in readdir(\"data/\" * population)\n        sample == \".DS_Store\" && continue # skip auxiliary files\n        push!(df, (sample, population))\n        refID_to_population[sample] = population\n    end\nend\nrefID_to_population","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"Dict{String,String} with 2709 entries:\n  \"HG01791\" => \"GBR\"\n  \"HG02736\" => \"PJL\"\n  \"HG00182\" => \"FIN\"\n  \"HG03914\" => \"BEB\"\n  \"HG00149\" => \"GBR\"\n  \"NA12156\" => \"CEU\"\n  \"HG02642\" => \"GWD\"\n  \"HG02851\" => \"GWD\"\n  \"NA19835\" => \"ASW\"\n  \"NA19019\" => \"LWK\"\n  \"HG01131\" => \"CLM\"\n  \"HG03725\" => \"ITU\"\n  \"HG03578\" => \"MSL\"\n  \"NA18550\" => \"CHB\"\n  \"HG02401\" => \"CDX\"\n  \"HG01350\" => \"CLM\"\n  \"HG03973\" => \"ITU\"\n  \"NA07000\" => \"CEU\"\n  \"HG01709\" => \"IBS\"\n  \"HG01395\" => \"PUR\"\n  \"HG02388\" => \"CDX\"\n  \"HG01980\" => \"PEL\"\n  \"HG01979\" => \"PEL\"\n  \"HG01122\" => \"CLM\"\n  \"HG03869\" => \"ITU\"\n  ⋮         => ⋮","category":"page"},{"location":"man/painting/#Step-3.-Compute-phase-information-using-MendelImpute","page":"Estimating ancestry","title":"Step 3. Compute phase information using MendelImpute","text":"","category":"section"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"This is equivalent to running a typical imputation. Please ensure that:","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"The output file name ends with .jlso (save output to ultra-compressed format)\nimpute = true (so the output contains the entire chromosome)","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"Note data used here is prepared in Detailed Example.","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"# compute each person's phase information\ntgtfile = \"target.chr22.typedOnly.masked.vcf.gz\"\nreffile = \"ref.chr22.maxd1000.excludeTarget.jlso\"\noutfile = \"mendel.imputed.jlso\"\n@time ph = phase(tgtfile, reffile, outfile=outfile, impute=true, max_d=1000);","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"Number of threads = 1\nImporting reference haplotype data...\n\n\n\u001b[32mComputing optimal haplotypes...100%|████████████████████| Time: 0:00:22\u001b[39m\n\n\nTotal windows = 1634, averaging ~ 508 unique haplotypes per window.\n\nTimings: \n    Data import                     = 12.8755 seconds\n        import target data             = 3.19177 seconds\n        import compressed haplotypes   = 9.68371 seconds\n    Computing haplotype pair        = 22.6357 seconds\n        BLAS3 mul! to get M and N      = 1.01138 seconds per thread\n        haplopair search               = 17.8065 seconds per thread\n        initializing missing           = 0.0905452 seconds per thread\n        allocating and viewing         = 0.325886 seconds per thread\n        index conversion               = 0.0097123 seconds per thread\n    Phasing by win-win intersection = 1.2638 seconds\n        Window-by-window intersection  = 0.520476 seconds per thread\n        Breakpoint search              = 0.231444 seconds per thread\n        Recording result               = 0.0500224 seconds per thread\n    Imputation                     = 3.0595 seconds\n        Imputing missing               = 0.0697154 seconds\n        Writing to file                = 2.98979 seconds\n\n    Total time                      = 39.9759 seconds\n\n 51.214539 seconds (109.80 M allocations: 6.143 GiB, 5.08% gc time)","category":"page"},{"location":"man/painting/#Estimate-admixture-proportions","page":"Estimating ancestry","title":"Estimate admixture proportions","text":"","category":"section"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"The composition will compute a list of percentages where composition[i] equals the sample's ancestry (in %) from populations[i]. Thus we simply have to plot the result. This illustration depends on data preparation above. ","category":"page"},{"location":"man/painting/#Step-1:-import-necessary-data","page":"Estimating ancestry","title":"Step 1: import necessary data","text":"","category":"section"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"# First import compressed reference panel\nreffile = \"ref.chr22.maxd1000.excludeTarget.jlso\"\ncompressed_Hunique = JLSO.load(reffile)[:compressed_Hunique]\npanelID = compressed_Hunique.sampleID\n\n# also need target sample's ancestry\ntgtfile = \"target.chr22.typedOnly.masked.vcf.gz\"\nreader = VCF.Reader(openvcf(tgtfile, \"r\"))\ntgtID  = VCF.header(reader).sampleID\nsample_population = [refID_to_population[id] for id in tgtID];","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"# here is our sample population (sample 1 is GBR, 4 is CHS, 84 is LWK...etc)\nsample_population","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"100-element Array{String,1}:\n \"GBR\"\n \"FIN\"\n \"CHS\"\n \"CHS\"\n \"CDX\"\n \"CDX\"\n \"PUR\"\n \"PUR\"\n \"PUR\"\n \"PUR\"\n \"GBR\"\n \"CLM\"\n \"IBS\"\n ⋮\n \"MXL\"\n \"ASW\"\n \"ASW\"\n \"TSI\"\n \"TSI\"\n \"TSI\"\n \"TSI\"\n \"TSI\"\n \"TSI\"\n \"TSI\"\n \"GIH\"\n \"GIH\"","category":"page"},{"location":"man/painting/#Step-2:-call-composition-function","page":"Estimating ancestry","title":"Step 2: call composition function","text":"","category":"section"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"The composition will compute a list of percentages where composition[i] equals the sample's ancestry (in %) from populations[i]. We are finally using the imputation result stored in ph.","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"populations = MendelImpute.unique_populations(refID_to_population)\n@time sample1_comp = composition(ph[1], panelID, refID_to_population) # origin GBR\n@time sample4_comp = composition(ph[4], panelID, refID_to_population) # origin CHS\n@time sample84_comp = composition(ph[84], panelID, refID_to_population) # origin LWK","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"  0.003716 seconds (28 allocations: 2.719 KiB)\n  0.000300 seconds (8 allocations: 1.250 KiB)\n  0.000320 seconds (8 allocations: 1.250 KiB)\n\n\n\n\n\n26-element Array{Float64,1}:\n 0.0320057171449708\n 0.004297435185340359\n 0.018110277693318744\n 0.002775975541728215\n 0.0014975185005183258\n 0.11653590812346927\n 0.010756755592052499\n 0.21362083454036596\n 0.03346971804515778\n 0.004278282270865305\n 0.0735579650986016\n 0.0003950288610479996\n 0.005562724597848649\n 0.013571036962730822\n 0.0639467932035883\n 0.0072230428714049385\n 0.0006930960925660357\n 0.19267353139042978\n 0.01657325630669562\n 0.06172744923879136\n 0.0003351760033134542\n 0.0043297557285170134\n 0.1120026526786548\n 0.006926172697041593\n 0.0027065462267561427\n 0.0004273494042246541","category":"page"},{"location":"man/painting/#Step-3:-Plot-the-percentages","page":"Estimating ancestry","title":"Step 3: Plot the percentages","text":"","category":"section"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"We computed the population percentages for sample 1, 4, and 84. Here sample1_comp[i] equals the sample's estimated ancestry (in %) from populations[i]. Thus we simply have to create a bar plot for each:","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"barplot = bar(sample1_comp, xticks=(1:1:26, populations), xrotation=50, grid=false, \n    ylabel = \"Ancestry proportions\", label=\"Sample 1 (GBR)\", alpha=0.8, legend=:top,\n    xtickfont=font(10), ytickfont=font(11), legendfont=font(9), yguidefontsize=18)\nbar!(barplot, sample4_comp, label=\"Sample 4 (CHS)\", alpha=0.8)\nbar!(barplot, sample84_comp, label=\"Sample 84 (LWK)\", alpha=0.8)","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"(Image: svg)","category":"page"},{"location":"man/painting/#Chromosome-painting","page":"Estimating ancestry","title":"Chromosome painting","text":"","category":"section"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"The main function is the paint function. For an imputed sample, it will convert each haplotype segment into a percentage indicating the segment's length in the chromosome. Then the list can be used for easy plotting. ","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"Note: this illustration depends on data preparation above. ","category":"page"},{"location":"man/painting/#Step-1:-Choose-your-colors","page":"Estimating ancestry","title":"Step 1: Choose your colors","text":"","category":"section"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"In this example, colors are arranged such that:","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"Blue ≈ European/American\nRed ≈ Asian\nGreen ≈ African","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"Of course, Julia lets you plot your favoriate colors. We pick our colors here: https://mdigi.tools/color-shades/#008000.","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"# generated here: https://mdigi.tools/color-shades/#008000\n# Blue ≈ European/American, Red ≈ Asian, Green ≈ Africa\ngoodcolors = [colorant\"#c8c8ff\", colorant\"#ffeaea\", colorant\"#ffbfbf\", colorant\"#a4a4ff\",\n    colorant\"#8080ff\", colorant\"#e3ffe3\", colorant\"#aaffaa\", colorant\"#71ff71\", \n    colorant\"#5b5bff\", colorant\"#ff9595\", colorant\"#39ff39\", colorant\"#ff6a6a\",\n    colorant\"#ff4040\", colorant\"#3737ff\", colorant\"#1212ff\", colorant\"#0000c8\", \n    colorant\"#0000a4\", colorant\"#00ff00\", colorant\"#ff1515\", colorant\"#00c600\", \n    colorant\"#ea0000\", colorant\"#bf0000\", colorant\"#008e00\", colorant\"#00005b\",\n    colorant\"#950000\", colorant\"#6a0000\"]","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"(Image: svg)","category":"page"},{"location":"man/painting/#Step-2:-Run-paint-funcion","page":"Estimating ancestry","title":"Step 2: Run paint funcion","text":"","category":"section"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"This function convert the imputed haplotype segments into a list of percentages (one list for each strand). This is simply a post-processing routine so that data can be used for easy plotting later.","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"populations = unique_populations(refID_to_population)\n@time sample1_s1_comp, sample1_s2_comp = paint(ph[1], panelID, refID_to_population)\n@time sample4_s1_comp, sample4_s2_comp = paint(ph[4], panelID, refID_to_population)\n@time sample84_s1_comp, sample84_s2_comp = paint(ph[84], panelID, refID_to_population);","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"  0.000257 seconds (12 allocations: 19.125 KiB)\n  0.000238 seconds (12 allocations: 20.375 KiB)\n  0.000253 seconds (12 allocations: 22.875 KiB)","category":"page"},{"location":"man/painting/#Step-3:-Generate-plots-for-painted-chromosomes","page":"Estimating ancestry","title":"Step 3: Generate plots for painted chromosomes","text":"","category":"section"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"We found the StatsPlots.jl package to be more useful for this purpose, although the code below still did the plotting in a very roundabout way. ","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"# assign a color to each haplotype segment\nsample1_s1_colors = [goodcolors[findfirst(x -> x == pop, populations)] for pop in sample1_s1_comp[2]]\nsample1_s1_colors = reshape(sample1_s1_colors, 1, length(sample1_s1_colors))\n\nsample1_s2_colors = [goodcolors[findfirst(x -> x == pop, populations)] for pop in sample1_s2_comp[2]]\nsample1_s2_colors = reshape(sample1_s2_colors, 1, length(sample1_s2_colors))\n\nsample4_s1_colors = [goodcolors[findfirst(x -> x == pop, populations)] for pop in sample4_s1_comp[2]]\nsample4_s1_colors = reshape(sample4_s1_colors, 1, length(sample4_s1_colors))\n\nsample4_s2_colors = [goodcolors[findfirst(x -> x == pop, populations)] for pop in sample4_s2_comp[2]]\nsample4_s2_colors = reshape(sample4_s2_colors, 1, length(sample4_s2_colors))\n\nsample84_s1_colors = [goodcolors[findfirst(x -> x == pop, populations)] for pop in sample84_s1_comp[2]]\nsample84_s1_colors = reshape(sample84_s1_colors, 1, length(sample84_s1_colors))\n\nsample84_s2_colors = [goodcolors[findfirst(x -> x == pop, populations)] for pop in sample84_s2_comp[2]]\nsample84_s2_colors = reshape(sample84_s2_colors, 1, length(sample84_s2_colors));","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"using StatsPlots, FixedPointNumbers\n\n# some tedious and roundabout routine for making a bad groupedplot\nsample1_s1l = length(sample1_s1_comp[1])\nsample1_s2l = length(sample1_s2_comp[1])\nsample4_s1l = length(sample4_s1_comp[1])\nsample4_s2l = length(sample4_s2_comp[1])\nsample84_s1l = length(sample84_s1_comp[1])\nsample84_s2l = length(sample84_s2_comp[1])\nmaxlen = max(sample1_s1l, sample1_s2l, sample4_s1l, sample4_s2l, sample84_s1l, sample84_s2l)\n\nmydata = zeros(6, maxlen)\ncopyto!(@view(mydata[1, 1:sample1_s1l]), sample1_s1_comp[1])\ncopyto!(@view(mydata[2, 1:sample1_s2l]), sample1_s2_comp[1])\ncopyto!(@view(mydata[3, 1:sample4_s1l]), sample4_s1_comp[1])\ncopyto!(@view(mydata[4, 1:sample4_s2l]), sample4_s2_comp[1])\ncopyto!(@view(mydata[5, 1:sample84_s1l]), sample84_s1_comp[1])\ncopyto!(@view(mydata[6, 1:sample84_s2l]), sample84_s2_comp[1])\n\nmycolors = Matrix{RGB{Normed{UInt8,8}}}(undef, 6, maxlen)\ncopyto!(@view(mycolors[1, 1:sample1_s1l]), sample1_s1_colors)\ncopyto!(@view(mycolors[2, 1:sample1_s2l]), sample1_s2_colors)\ncopyto!(@view(mycolors[3, 1:sample4_s1l]), sample4_s1_colors)\ncopyto!(@view(mycolors[4, 1:sample4_s2l]), sample4_s2_colors)\ncopyto!(@view(mycolors[5, 1:sample84_s1l]), sample84_s1_colors)\ncopyto!(@view(mycolors[6, 1:sample84_s2l]), sample84_s2_colors)\n\n# axis labels\nxnames = [\"Sample 1 hap1\", \"Sample 1 hap2\", \"Sample 4 hap1\", \"Sample 4 hap2\", \"Sample 84 hap1\", \"Sample 84 hap2\"]\nynames = [\"SNP 1\", \"SNP 208k\", \"SNP 417k\"]\n\n# final plot\nchrom_plt = groupedbar(mydata, bar_position = :stack, bar_width=0.7, label=:none, \n    lw = 0, color=mycolors, xticks=(1:1:6, xnames), yticks=(0:0.5:1, ynames),\n    ytickfont=font(12), xtickfont=font(12), xrotation=20)","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"(Image: svg)","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"For more details, please refer to our paper, or file an issue on GitHub. ","category":"page"},{"location":"man/Phasing+and+Imputation/#Preparing-Target-Data","page":"Phasing and Imputation","title":"Preparing Target Data","text":"","category":"section"},{"location":"man/Phasing+and+Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"MendelImpute accepts VCF and PLINK files. Please make sure the following are true:","category":"page"},{"location":"man/Phasing+and+Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"VCF file ends in .vcf or .vcf.gz\nFor PLINK files, all trios (.bim, .bed, .fam) are present in the same directory\nEach file contains only 1 chromosome\nEvery record (SNP) is present in the reference panel. If this is untrue, you must match markers in 2 VCF files. \nGiven a SNP, it's position is the same in target data and reference panel. MendelImpute use SNP position internally to align markers. \nThe position of every SNP is unique (so multiallelic markers should be excluded instead of split)","category":"page"},{"location":"man/Phasing+and+Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"If the last criteria is not met, our code may or may not work. File an issue to let us know.","category":"page"},{"location":"man/Phasing+and+Imputation/#Preparing-Reference-Haplotype-Panel","page":"Phasing and Imputation","title":"Preparing Reference Haplotype Panel","text":"","category":"section"},{"location":"man/Phasing+and+Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"Reference panels must be compressed into .jlso format first using the compress_haplotypes function. One must specify d: the maximum number of unique haplotypes per window. Larger d slows down computation, but increases accuracy. For most purposes, we recommend d approx 1000. A larger d may be needed for TOPMed data. ","category":"page"},{"location":"man/Phasing+and+Imputation/#Detailed-Example","page":"Phasing and Imputation","title":"Detailed Example","text":"","category":"section"},{"location":"man/Phasing+and+Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"We use the 1000 genomes chromosome 22 as an example. As show below, this data contains 424147 SNPs and 2504 samples.","category":"page"},{"location":"man/Phasing+and+Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"# load necessary packages in Julia\nusing VCFTools\n\n# compute simple summary statistics\ndata = \"chr22.1kg.phase3.v5a.vcf.gz\"\n@show nrecords(data)\n@show nsamples(data);","category":"page"},{"location":"man/Phasing+and+Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"nrecords(data) = 424147\nnsamples(data) = 2504","category":"page"},{"location":"man/Phasing+and+Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"More summary statistics can be computed using the gtstats function in VCFTools.jl, with example usage here.","category":"page"},{"location":"man/Phasing+and+Imputation/#Step-1:-generating-realistic-reference-and-target-data","page":"Phasing and Imputation","title":"Step 1: generating realistic reference and target data","text":"","category":"section"},{"location":"man/Phasing+and+Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"First we generate a reference panel and imputation target based on the 1000 genomes data. More specifically, we take the 1000 genomes chromosome 22 and divide it so that ","category":"page"},{"location":"man/Phasing+and+Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"The first 100 samples are used as imputation targets, where\n100k SNPs with minor allele frequency ge 005 are randomly selected to be the typed positions. \n0.1% of typed SNPs are masked (mimicking GWAS errors)\nGenotypes are unphased\nThe remaining 2404 samples are used as reference haplotypes. \nSNPs with duplicate positions are filtered out.\nAll multiallelic markers are filtered out.","category":"page"},{"location":"man/Phasing+and+Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"Instruction: execute the code below in a Julia session or a Jupyter notebook:","category":"page"},{"location":"man/Phasing+and+Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"# load necessary packages in Julia\nusing MendelImpute\nusing VCFTools\nusing Random\n\n# set random seed for reproducibility\nRandom.seed!(2020)\n\n# download example data \ndata = \"chr22.1kg.phase3.v5a.vcf.gz\"\nif !isfile(data) \n    download(\"http://bochet.gcc.biostat.washington.edu/beagle/1000_Genomes_phase3_v5a/b37.vcf/chr22.1kg.phase3.v5a.vcf.gz\")\nend\n\n# remove SNPs with the same positions, keep all samples, save result into new file\nSNPs_to_keep = .!find_duplicate_marker(data) \n@time VCFTools.filter(data, SNPs_to_keep, 1:nsamples(data), des = \"chr22.uniqueSNPs.vcf.gz\")\n\n# summarize data\ntotal_snps, samples, _, _, _, maf_by_record, _ = gtstats(\"chr22.uniqueSNPs.vcf.gz\")\n\n# generate target file with 100 samples and 100k snps with maf>0.05\nn = 100\np = 100000\nrecord_idx = falses(total_snps)\nlarge_maf = findall(x -> x > 0.05, maf_by_record)  \nRandom.shuffle!(large_maf)\nrecord_idx[large_maf[1:p]] .= true\nsample_idx = falses(samples)\nsample_idx[1:n] .= true\nRandom.shuffle!(sample_idx)\n@time VCFTools.filter(\"chr22.uniqueSNPs.vcf.gz\", record_idx, sample_idx, \n    des = \"target.chr22.typedOnly.vcf.gz\", allow_multiallelic=false)\n\n# unphase and mask 0.1% entries in target file\nmasks = falses(p, n)\nmissingprop = 0.001\nfor j in 1:n, i in 1:p\n    rand() < missingprop && (masks[i, j] = true)\nend\n@time mask_gt(\"target.chr22.typedOnly.vcf.gz\", masks, \n    des=\"target.chr22.typedOnly.masked.vcf.gz\", unphase=true)\n\n# generate target panel with all snps (this file contains true phase and genotypes)\n@time VCFTools.filter(\"chr22.uniqueSNPs.vcf.gz\", 1:total_snps, \n    sample_idx, des = \"target.chr22.full.vcf.gz\", allow_multiallelic=false)\n\n# generate reference panel with 2404 samples\n@time VCFTools.filter(\"chr22.uniqueSNPs.vcf.gz\", 1:total_snps, .!sample_idx, \n    des = \"ref.chr22.excludeTarget.vcf.gz\", allow_multiallelic=false)","category":"page"},{"location":"man/Phasing+and+Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"┌ Info: Precompiling MendelImpute [e47305d1-6a61-5370-bc5d-77554d143183]\n└ @ Base loading.jl:1278\n\u001b[32mfinding duplicate markers...100%|███████████████████████| Time: 0:03:56\u001b[39m\n\u001b[32mfiltering vcf file...100%|██████████████████████████████| Time: 0:04:46\u001b[39m\n\n\n292.131527 seconds (3.20 G allocations: 301.789 GiB, 7.89% gc time)\n\n\n\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:04:02\u001b[39m\n\u001b[32mfiltering vcf file...100%|██████████████████████████████| Time: 0:03:59\u001b[39m\n\n\n244.425505 seconds (3.18 G allocations: 301.694 GiB, 9.69% gc time)\n  1.935526 seconds (20.00 M allocations: 1.491 GiB, 6.33% gc time)\n\n\n\u001b[32mfiltering vcf file...100%|██████████████████████████████| Time: 0:04:10\u001b[39m\n\n\n255.505399 seconds (3.27 G allocations: 317.749 GiB, 9.95% gc time)\n\n\n\u001b[32mfiltering vcf file...100%|██████████████████████████████| Time: 0:07:27\u001b[39m\n\n\n453.383147 seconds (6.16 G allocations: 566.535 GiB, 10.16% gc time)","category":"page"},{"location":"man/Phasing+and+Imputation/#Output-explanation:","page":"Phasing and Imputation","title":"Output explanation:","text":"","category":"section"},{"location":"man/Phasing+and+Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"You just generated reference and target VCF files:","category":"page"},{"location":"man/Phasing+and+Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"ref.chr22.excludeTarget.vcf.gz: Reference haplotype panel with 2404 samples\ntarget.chr22.typedOnly.masked.vcf.gz: Imputation target file containing 100 samples at 100k SNPs. All genotypes are unphased and contains 0.1% missing data. ","category":"page"},{"location":"man/Phasing+and+Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"You also generated/downloaded:","category":"page"},{"location":"man/Phasing+and+Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"chr22.1kg.phase3.v5a.vcf.gz: The original chromosome 22 data downloaded from Beagle's website.\nchr22.uniqueSNPs.vcf.gz: This is the original chromosome 22 data excluding duplicate records (SNPs) by checking marker positions. The first SNP is included but all subsequent SNPs are removed. \ntarget.chr22.full.vcf.gz: The complete data for imputation target, used for checking imputation accuracy. All genotypes are phased and non-missing. \ntarget.chr22.typedOnly.vcf.gz: Complete target data on just the typed SNPs. All genotypes are phased and non-missing. Just by-producted for generating other files; not used for anything downstream.","category":"page"},{"location":"man/Phasing+and+Imputation/#Step-2:-generating-.jlso-compressed-reference-panel","page":"Phasing and Imputation","title":"Step 2: generating .jlso compressed reference panel","text":"","category":"section"},{"location":"man/Phasing+and+Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"MendelImpute requires one to pre-process the reference panel for faster reading. This is achieved via the compress_haplotypes function.","category":"page"},{"location":"man/Phasing+and+Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"max_d = 1000 # maximum number of unique haplotypes per window\nreffile = \"ref.chr22.excludeTarget.vcf.gz\"\ntgtfile = \"target.chr22.typedOnly.masked.vcf.gz\"\noutfile = \"ref.chr22.maxd1000.excludeTarget.jlso\"\n@time compress_haplotypes(reffile, tgtfile, outfile, max_d)","category":"page"},{"location":"man/Phasing+and+Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"\u001b[32mimporting reference data...100%|████████████████████████| Time: 0:01:55\u001b[39m\n\n\n284.456419 seconds (2.08 G allocations: 209.110 GiB, 10.89% gc time)","category":"page"},{"location":"man/Phasing+and+Imputation/#Step-3:-Run-imputation-and-phasing","page":"Phasing and Imputation","title":"Step 3: Run imputation and phasing","text":"","category":"section"},{"location":"man/Phasing+and+Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"The main function is the phase function. The code below runs it in a single thread:","category":"page"},{"location":"man/Phasing+and+Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"reffile = \"ref.chr22.maxd1000.excludeTarget.jlso\" # jlso reference file\ntgtfile = \"target.chr22.typedOnly.masked.vcf.gz\"  # target genotype file\noutfile = \"mendel.imputed.chr22.vcf.gz\"           # output file name\nd       = 1000 # this should be the equal to max_d in previous code block\nphase(tgtfile, reffile; outfile=outfile, max_d = d);","category":"page"},{"location":"man/Phasing+and+Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"Importing reference haplotype data...\n\n\n\u001b[32mComputing optimal haplotypes...100%|████████████████████| Time: 0:00:21\u001b[39m\n\n\nTotal windows = 1634, averaging ~ 508 unique haplotypes per window.\n\nTimings: \n    Data import                     = 11.719 seconds\n        import target data             = 2.23359 seconds\n        import compressed haplotypes   = 9.48538 seconds\n    Computing haplotype pair        = 22.1275 seconds\n        BLAS3 mul! to get M and N      = 0.978357 seconds per thread\n        haplopair search               = 17.6055 seconds per thread\n        initializing missing           = 0.092384 seconds per thread\n        allocating and viewing         = 0.300453 seconds per thread\n        index conversion               = 0.00979729 seconds per thread\n    Phasing by win-win intersection = 1.45252 seconds\n        Window-by-window intersection  = 0.571672 seconds per thread\n        Breakpoint search              = 0.319126 seconds per thread\n        Recording result               = 0.0618488 seconds per thread\n    Imputation                     = 3.24156 seconds\n        Imputing missing               = 0.149169 seconds\n        Writing to file                = 3.09239 seconds\n\n    Total time                      = 38.6959 seconds","category":"page"},{"location":"man/Phasing+and+Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"Inputs after the first ; are all optional, which is why an equal sign is needed. If left not specified, MendelImpute uses the default values. A list of optional inputs can be found in the phase( ) API. The second ; hides the output, or else the screen will be too jammed. ","category":"page"},{"location":"man/Phasing+and+Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"note: Note\nTo run MendelImpute in parallel, type export JULIA_NUM_THREADS=4 before starting Julia. For optimal performance, set threads equal to the number of physical cores on your machine. Verify the Julia session is running is parallel by executing Threads.nthreads() in Julia. Finally, set the number of BLAS threads to be 1 by using LinearAlgebra; BLAS.set_num_threads(1), to avoid oversubscription. ","category":"page"},{"location":"man/Phasing+and+Imputation/#Step-4:-(only-for-simulated-data)-check-imputation-accuracy","page":"Phasing and Imputation","title":"Step 4: (only for simulated data) check imputation accuracy","text":"","category":"section"},{"location":"man/Phasing+and+Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"Since we simulated data, we can check imputation accuracy.","category":"page"},{"location":"man/Phasing+and+Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"X_truth  = convert_gt(Float64, \"target.chr22.full.vcf.gz\")    # import true genotypes\nX_mendel = convert_gt(Float64, \"mendel.imputed.chr22.vcf.gz\") # import imputed genotypes\nn, p = size(X_mendel)\nprintln(\"error overall = $(sum(X_mendel .!= X_truth) / n / p)\")","category":"page"},{"location":"man/Phasing+and+Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"error overall = 0.005397602533930585","category":"page"},{"location":"man/Phasing+and+Imputation/#Run-MendelImpute-as-script","page":"Phasing and Imputation","title":"Run MendelImpute as script","text":"","category":"section"},{"location":"man/Phasing+and+Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"If you don't want to run MendelImpute.jl in a Julia session (e.g. you want to run batch jobs on a cluster), you can do so by putting the code above in a Julia file. For instance, create a file called impute.jl which contains:","category":"page"},{"location":"man/Phasing+and+Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"# place these code in a file called impute.jl\nusing MendelImpute, VCFTools\nreffile = ARGS[1] # first command line argument\ntgtfile = ARGS[2] # second command line argument\nphase(tgtfile, reffile; outfile=\"mendel.imputed.chr22.vcf.gz\", max_d = 1000)","category":"page"},{"location":"man/Phasing+and+Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"Then in the terminal/command-prompt, you can do","category":"page"},{"location":"man/Phasing+and+Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"julia impute.jl ref.chr22.maxd1000.excludeTarget.jlso target.chr22.typedOnly.masked.vcf.gz","category":"page"},{"location":"man/ultra+compress/#Ultra-compressed-format","page":"Ultra compression","title":"Ultra-compressed format","text":"","category":"section"},{"location":"man/ultra+compress/","page":"Ultra compression","title":"Ultra compression","text":"One can optionally save/load ultra-compressed phased genotypes after imputation. Ultra-compression is nothing fancy. Instead of converting haplotype segments into genotypes, this protocol simply saves the starting position and the correct haplotype label. We put this result into our own data structure, and saving/loading is achieved by the JLSO package. ","category":"page"},{"location":"man/ultra+compress/#Saving","page":"Ultra compression","title":"Saving","text":"","category":"section"},{"location":"man/ultra+compress/","page":"Ultra compression","title":"Ultra compression","text":"Appending .jlso to the output file name will signal MendelImpute to save data in ultra-compressed format. For admixture estimation, we strongly recommend one to save in .jlso format.","category":"page"},{"location":"man/ultra+compress/","page":"Ultra compression","title":"Ultra compression","text":"# first load all necessary packages\nusing MendelImpute\nusing VCFTools\n\n# compute each person's phase information\ntgtfile = \"target.chr22.typedOnly.masked.vcf.gz\"\nreffile = \"ref.chr22.maxd1000.excludeTarget.jlso\"\noutfile = \"mendel.imputed.jlso\" # output file name ends in jlso!\n@time phaseinfo = phase(tgtfile, reffile, outfile=outfile, impute=true, max_d=1000);","category":"page"},{"location":"man/ultra+compress/","page":"Ultra compression","title":"Ultra compression","text":"Number of threads = 1\nImporting reference haplotype data...\n\n\n\u001b[32mComputing optimal haplotypes...100%|████████████████████| Time: 0:00:22\u001b[39m\n\n\nTotal windows = 1634, averaging ~ 508 unique haplotypes per window.\n\nTimings: \n    Data import                     = 14.2706 seconds\n        import target data             = 3.27572 seconds\n        import compressed haplotypes   = 10.9948 seconds\n    Computing haplotype pair        = 22.7159 seconds\n        BLAS3 mul! to get M and N      = 1.00284 seconds per thread\n        haplopair search               = 18.0964 seconds per thread\n        initializing missing           = 0.095897 seconds per thread\n        allocating and viewing         = 0.310543 seconds per thread\n        index conversion               = 0.00992562 seconds per thread\n    Phasing by win-win intersection = 1.30819 seconds\n        Window-by-window intersection  = 0.525698 seconds per thread\n        Breakpoint search              = 0.275337 seconds per thread\n        Recording result               = 0.0496237 seconds per thread\n    Imputation                     = 2.84315 seconds\n        Imputing missing               = 0.0505533 seconds\n        Writing to file                = 2.7926 seconds\n\n    Total time                      = 41.2741 seconds\n\n 58.892784 seconds (137.79 M allocations: 7.481 GiB, 5.92% gc time)","category":"page"},{"location":"man/ultra+compress/","page":"Ultra compression","title":"Ultra compression","text":"The object saved to mendel.imputed.jlso is literally the phaseinfo variable. We can inspect its element:","category":"page"},{"location":"man/ultra+compress/","page":"Ultra compression","title":"Ultra compression","text":"# look at sample 1's haplotype segments\nhaplotype_labels = phaseinfo[1].strand1.haplotypelabel # strand1\nhaplotype_start = phaseinfo[1].strand1.start # strand1\n[haplotype_start haplotype_labels]","category":"page"},{"location":"man/ultra+compress/","page":"Ultra compression","title":"Ultra compression","text":"547×2 Array{Int64,2}:\n      1  4119\n    236   887\n    423   272\n    622    12\n    754   124\n    802     4\n    824    24\n    968  1282\n   1125  1741\n   1202  4543\n   1691  1198\n   3031    22\n   3521    18\n      ⋮  \n 411702   877\n 412362    74\n 413734  3849\n 413868   248\n 414456    31\n 414552  3187\n 414989  4481\n 415807     5\n 416108   143\n 416353  1276\n 416844    71\n 417084   311","category":"page"},{"location":"man/ultra+compress/#Loading","page":"Ultra compression","title":"Loading","text":"","category":"section"},{"location":"man/ultra+compress/","page":"Ultra compression","title":"Ultra compression","text":"The function convert_compressed will load the ultra-compressed data into genotype matrices and the original phaseinfo data structure. ","category":"page"},{"location":"man/ultra+compress/","page":"Ultra compression","title":"Ultra compression","text":"Note: Decompressing requires loading the original haplotype reference panel. ","category":"page"},{"location":"man/ultra+compress/","page":"Ultra compression","title":"Ultra compression","text":"tgtfile = \"mendel.imputed.jlso\" # ultra-compressed genotypes after phasing & imputation\nreffile = \"ref.chr22.excludeTarget.vcf.gz\" # original haplotype reference file\nX1, X2, phaseinfo, sampleID, H = convert_compressed(Float64, tgtfile, reffile);","category":"page"},{"location":"man/ultra+compress/","page":"Ultra compression","title":"Ultra compression","text":"\u001b[32mimporting reference data...100%|████████████████████████| Time: 0:01:52\u001b[39m","category":"page"},{"location":"man/ultra+compress/","page":"Ultra compression","title":"Ultra compression","text":"Check this compression protocol exhibit same error rate with standard VCF compression. Note that X1, X2, and H are transposed. ","category":"page"},{"location":"man/ultra+compress/","page":"Ultra compression","title":"Ultra compression","text":"X_truth  = convert_gt(Float64, \"target.chr22.full.vcf.gz\") # import true genotypes\nX_mendel = (X1 + X2)' # transpose X1 and X2\nn, p = size(X_mendel)\nprintln(\"error overall = $(sum(X_mendel .!= X_truth) / n / p)\")","category":"page"},{"location":"man/ultra+compress/","page":"Ultra compression","title":"Ultra compression","text":"error overall = 0.005397602533930585","category":"page"},{"location":"man/performance/#Performance-gotchas","page":"Performance Gotchas","title":"Performance gotchas","text":"","category":"section"},{"location":"man/performance/#Gotcha-1:-Run-MendelImpute-in-parallel","page":"Performance Gotchas","title":"Gotcha 1: Run MendelImpute in parallel","text":"","category":"section"},{"location":"man/performance/","page":"Performance Gotchas","title":"Performance Gotchas","text":"To run MendelImpute.jl in parallel,","category":"page"},{"location":"man/performance/","page":"Performance Gotchas","title":"Performance Gotchas","text":"Execute export JULIA_NUM_THREADS=4 before starting Julia. We recommend number of threads equal to the number of physical CPU cores on your machine. \nVerify the Julia session is running is parallel by executing Threads.nthreads() in Julia\nSet the number of BLAS threads to be 1 by using LinearAlgebra; BLAS.set_num_threads(1). This avoids oversubscription. ","category":"page"},{"location":"man/performance/","page":"Performance Gotchas","title":"Performance Gotchas","text":"note: Note\nDo not use hyper-threading. In other words, don't set the number of Julia threads to be more than number of physical CPU cores. Hyperthreading is valuable for I/O operations (in our experience), but not for linear algebra routines used throughout MendelImpute. ","category":"page"},{"location":"man/performance/#Gotcha-2:-max_d-too-high-(or-too-low)","page":"Performance Gotchas","title":"Gotcha 2: max_d too high (or too low)","text":"","category":"section"},{"location":"man/performance/","page":"Performance Gotchas","title":"Performance Gotchas","text":"When you compress the haplotype panels into a .jlso format, you specified max_d which is the maximum number of unique haplotypes per window. We generally recommend using max_d = 1000, BUT 1000 may be too small if you use a reference panel larger than HRC. In that case, you can try larger max_d, which will improve error rate. ","category":"page"},{"location":"man/performance/#Symptoms-for-max_d-too-high:","page":"Performance Gotchas","title":"Symptoms for max_d too high:","text":"","category":"section"},{"location":"man/performance/","page":"Performance Gotchas","title":"Performance Gotchas","text":"Computing optimal haplotypes is too slow. In particular, the timing for haplopair search is too high. ","category":"page"},{"location":"man/performance/#Symptoms-for-max_d-too-low:","page":"Performance Gotchas","title":"Symptoms for max_d too low:","text":"","category":"section"},{"location":"man/performance/","page":"Performance Gotchas","title":"Performance Gotchas","text":"Too few typed SNPs per window indicates max_d is set too low. You can calculate the number of typed SNPs per window by dividing the total number of SNPs in the target file by the total windows (a number that will be output after every run). Ideally you want an average of 400 typed SNPs per window, but something as low as 50 still works. Something like 10~20 is too low. ","category":"page"},{"location":"man/performance/#I-really-want-to-use-a-high-max_d","page":"Performance Gotchas","title":"I really want to use a high max_d","text":"","category":"section"},{"location":"man/performance/","page":"Performance Gotchas","title":"Performance Gotchas","text":"A high max_d generally improve error, so it is understandable you want to do so. If a high max_d value runs too slow, try setting stepwise = 100 and max_haplotypes to a number that is close to 1000. This avoids searching the global minimizer of the least-squares problem for windows that have more than max_haplotypes number of unique haplotypes. Setting thinning_factor instead of stepwise have a similar effect. Details for these 2 heuristic searches are explained in the appendix of our paper. ","category":"page"},{"location":"man/performance/#Gotcha-3:-You-used-memory-swap","page":"Performance Gotchas","title":"Gotcha 3: You used memory swap","text":"","category":"section"},{"location":"man/performance/","page":"Performance Gotchas","title":"Performance Gotchas","text":"While MendelImpute uses the least RAM compared to competing softwares (as of 2020), it is still possible for large imputation problems to consume all available RAM. If this happens, Julia will first try to use swap before crashing (until all of swap is consumed). Monitor your RAM usage constantly to make sure this doesn't happen. On Mac/Linux machines, the top or htop command will monitor this information. Alternatively, the /usr/bin/time command will automatically records max RAM usage for job and whether any swap had been performed. ","category":"page"},{"location":"man/performance/","page":"Performance Gotchas","title":"Performance Gotchas","text":"If you do not have the above issues and your code is still running slow, file an issue on GitHub and we will take a look at it ASAP. ","category":"page"},{"location":"#MendelImpute.jl","page":"Home","title":"MendelImpute.jl","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Fast genotype imputation, phasing, and admixture estimation!","category":"page"},{"location":"","page":"Home","title":"Home","text":"MendelImpute.jl is the fastest and least memory-consuming software for phasing and genotype imputation, as of 2020. It is also capable of ancestry estimation.","category":"page"},{"location":"#Package-Features","page":"Home","title":"Package Features","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Built-in support for imputing genotypes stored in VCF files (.vcf, .vcf.gz) or PLINK files.\nOut-of-the-box multithreaded (shared memory) parallelism. \nAdmixture estimation, with code examples to make pretty plots!\nUltra-compressed file for phased genotypes.\nImputation on dosage data.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Given a target genotype file (phased or unphased and may contain missing data) and a reference haplotype file (phased, no missing), our software imputes every SNP in the reference file to the target file, outputing phased or unphased genotypes. Like many other software, SNPs typed in target must all be present in the reference panel. ","category":"page"},{"location":"#Installation","page":"Home","title":"Installation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Download and install Julia. Within Julia, copy and paste the following: ","category":"page"},{"location":"","page":"Home","title":"Home","text":"using Pkg\nPkg.add(PackageSpec(url=\"https://github.com/OpenMendel/SnpArrays.jl.git\"))\nPkg.add(PackageSpec(url=\"https://github.com/OpenMendel/VCFTools.jl.git\"))\nPkg.add(PackageSpec(url=\"https://github.com/OpenMendel/MendelImpute.jl.git\"))","category":"page"},{"location":"","page":"Home","title":"Home","text":"This package supports Julia v1.5+.","category":"page"},{"location":"#Manual-Outline","page":"Home","title":"Manual Outline","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Pages = [\n    \"man/Phasing+and+Imputation.md\"\n    \"man/performance.md\"\n    \"man/painting.md\"\n    \"man/ultra+compress.md\"\n    \"man/api.md\"\n]\nDepth = 2","category":"page"},{"location":"man/api/#API","page":"API","title":"API","text":"","category":"section"},{"location":"man/api/","page":"API","title":"API","text":"Documentation for MendelImpute.jl's functions.","category":"page"},{"location":"man/api/#Index","page":"API","title":"Index","text":"","category":"section"},{"location":"man/api/","page":"API","title":"API","text":"Pages = [\"api.md\"]","category":"page"},{"location":"man/api/#Functions","page":"API","title":"Functions","text":"","category":"section"},{"location":"man/api/","page":"API","title":"API","text":"phase\ncompress_haplotypes\npaint\ncomposition\nunique_populations\nconvert_compressed","category":"page"},{"location":"man/api/#MendelImpute.phase","page":"API","title":"MendelImpute.phase","text":"phase(tgtfile::String, reffile::String; [outfile::String], [impute::Bool],\n    [phase::Bool], [dosage::Bool], [max_d::Int], [recreen::Bool], \n    [max_haplotypes::Int], [stepwise::Int], [thinning_factor::Int], \n    [scale_allelefreq::Bool], [dynamic_programming::Bool])\n\nMain function of MendelImpute program. Phasing (haplotying) of tgtfile from a pool of haplotypes reffile by sliding windows and saves result in outfile. All SNPs in tgtfile must be present in reffile. \n\nInput\n\ntgtfile: VCF or PLINK files. VCF files should end in .vcf or .vcf.gz.   PLINK files should exclude .bim/.bed/.fam suffixes but the trio must all   be present in the same directory.\nreffile: Reference haplotype file ending in .vcf, .vcf.gz, or .jlso    (compressed binary files).\n\nOptional Inputs\n\noutfile: output filename ending in .vcf.gz, .vcf, or .jlso. VCF output   genotypes will have no missing data. If ending in .jlso, will output   ultra-compressed data structure recording HaplotypeMosaicPairs for    each sample\nimpute: If true, imputes every SNPs in reffile to tgtfile. Otherwise   only missing snps in tgtfile will be imputed.\nphase: If true, all output genotypes will be phased. Otherwise all   output genotypes will be unphased.\ndosage: If true, will assume target matrix are dosages for imputation. Note   this means the genotype matrix will be entirely    single precision. \nmax_d: Maximum number of unique haplotypes in each window. Note this number   is used in the compression step and nowhere else. \nrescreen: This option saves a number of top haplotype pairs when solving   the least squares objective, and re-minimize least squares on just   observed data.\nmax_haplotypes Maximum number of haplotypes for using to global search.    This number should be specified along with stepscreen or thinning_factor\nstepwise: This option solves the least squares objective by first finding   stepwise top haplotypes using a stepwise heuristic then finds the next   haplotype using global search.\nthinning_factor: This option solves the least squares objective on only   thining_factor unique haplotypes.\nscale_allelefreq: Boolean indicating whether to give rare SNPs more weight   scaled by wᵢ = 1 / √2p(1-p) where max weight is 2. \ndynamic_programming: Boolean indicating whether to phase with a global    search that finds the longest haplotype stretch over all windows.\n\n\n\n\n\n","category":"function"},{"location":"man/api/#MendelImpute.compress_haplotypes","page":"API","title":"MendelImpute.compress_haplotypes","text":"compress_haplotypes(reffile::String, tgtfile::String, outfile::String, d::Int)\n\nCuts a haplotype matrix reffile into windows of variable width so that each window has less than d unique haplotypes. Saves result to outfile as a compressed binary format. All SNPs in tgtfile must be present in reffile. \n\nWhy is tgtfile required?\n\nThe unique haplotypes in each window is computed on the typed SNPs only.  A genotype matrix tgtfile is used to identify the typed SNPs. In the future,  hopefully we can pre-compute compressed haplotype panels for all genotyping  platforms and provide them as downloadable files. But currently, users must run this function by themselves. \n\nInputs\n\nreffile: reference haplotype file name (ends in .vcf or .vcf.gz)\ntgtfile: target genotype file name (ends in .vcf or .vcf.gz)\noutfile: Output file name (ends in .jlso)\nd: Max number of unique haplotypes per window (recommended d = 1000). \n\n\n\n\n\n","category":"function"},{"location":"man/api/#MendelImpute.paint","page":"API","title":"MendelImpute.paint","text":"paint(sample_phase::HaplotypeMosaicPair, panelID::Vector{String},\n    refID_to_population::Dict{String, String}, populations::Vector{String})\n\nConverts a person's phased haplotype lengths into segments of percentages. This function is used for easier plotting a \"painted chromosome\".\n\nArguments\n\nsample_phase: A HaplotypeMosaicPair storing phase information for a   sample, includes haplotype start position and haplotype label.\npanelID: Sample ID's in the reference haplotype panel\nrefID_to_population: A dictionary mapping each ID in the haplotype    reference panel to its population origin. \n\nOptional inputs\n\npopulations: A unique list of populations present in refID_to_population\n\nOutput\n\ncomposition: A list of percentages where composition[i] equals the   sample's ancestry (in %) from populations[i] \n\n\n\n\n\n","category":"function"},{"location":"man/api/#MendelImpute.composition","page":"API","title":"MendelImpute.composition","text":"composition(sample_phase::HaplotypeMosaicPair, panelID::Vector{String}, \n    refID_to_population::Dict{String, String}, [populations::Vector{String}])\n\nComputes a sample's chromosome composition based on phase information. This function is used for easier plotting a person's admixed proportions.\n\nArguments\n\nsample_phase: A HaplotypeMosaicPair storing phase information for a   sample, includes haplotype start position and haplotype label.\npanelID: Sample ID's in the reference haplotype panel\nrefID_to_population: A dictionary mapping each ID in the haplotype    reference panel to its population origin. \n\nOptional inputs\n\npopulations: A unique list of populations present in refID_to_population\n\nOutput\n\ncomposition: A list of percentages where composition[i] equals the   sample's ancestry (in %) from populations[i] \n\n\n\n\n\n","category":"function"},{"location":"man/api/#MendelImpute.unique_populations","page":"API","title":"MendelImpute.unique_populations","text":"unique_populations(x::Dict{String, String})\n\nComputes the unique list of populations, preserving order. x is a Dict where each sample is a key and populations are values. \n\n\n\n\n\n","category":"function"},{"location":"man/api/#MendelImpute.convert_compressed","page":"API","title":"MendelImpute.convert_compressed","text":"convert_compressed(t<:Real, phaseinfo::String, reffile::String)\n\nConverts phaseinfo into a phased genotype matrix of type t using the full reference haplotype panel H \n\nInputs\n\nt: Type of matrix. If bool, genotypes are converted to a BitMatrix\nphaseinfo: Vector of HaplotypeMosaicPairs stored in .jlso format\nreffile: The complete (uncompressed) haplotype reference file\n\nOutput\n\nX1: allele 1 of the phased genotype. Each column is a sample. X = X1 + X2. \nX2: allele 2 of the phased genotype. Each column is a sample. X = X1 + X2. \nphase: the original data structure after phasing and imputation.\nsampleID: The ID's of each imputed person. \nH: the complete reference haplotype panel.\n\n\n\n\n\nconvert_compressed(t<:Real, phaseinfo::Vector{HaplotypeMosaicPair}, H::AbstractMatrix)\n\nColumns of H are haplotypes.\n\n\n\n\n\n","category":"function"}]
}
